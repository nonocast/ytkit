"""
YouTubeå·¥å…·é›† - transcriptså‘½ä»¤
"""
import click
import os
import re
import json
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import WebVTTFormatter
from tools.llm_processor import LLMProcessor


def check_vtt_file(original_dir):
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨è‹±æ–‡VTTæ–‡ä»¶"""
    youtube_file = os.path.join(original_dir, '.youtube')
    
    if not os.path.exists(youtube_file):
        click.echo("âŒ é”™è¯¯ï¼šå½“å‰ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .youtube æ–‡ä»¶")
        click.echo("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ ytkit init å‘½ä»¤åˆå§‹åŒ–é¡¹ç›®")
        return None
    
    # è¯»å–URLè·å–è§†é¢‘ID
    try:
        with open(youtube_file, 'r', encoding='utf-8') as f:
            url = f.read().strip()
        
        m = re.search(r"[?&]v=([a-zA-Z0-9_-]{11})", url)
        video_id = m.group(1) if m else None
        
        if not video_id:
            click.echo("âŒ é”™è¯¯ï¼šæ— æ³•ä»URLä¸­æå–è§†é¢‘ID")
            return None
        
        vtt_file = os.path.join(original_dir, f'{video_id}.en.vtt')
        
        if not os.path.exists(vtt_file):
            click.echo(f"âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°è‹±æ–‡VTTæ–‡ä»¶ {vtt_file}")
            click.echo("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ ytkit download å‘½ä»¤ä¸‹è½½å­—å¹•")
            return None
        
        click.echo(f"âœ… æ‰¾åˆ°VTTæ–‡ä»¶: {vtt_file}")
        return video_id, vtt_file, url
        
    except Exception as e:
        click.echo(f"âŒ è¯»å– .youtube æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None


def parse_vtt_file(vtt_file):
    """è§£æVTTæ–‡ä»¶ï¼Œæå–å­—å¹•æ•°æ®"""
    click.echo(f"ğŸ“ è§£æVTTæ–‡ä»¶: {vtt_file}")
    
    try:
        with open(vtt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ¸…ç†å†…å®¹ä¸­çš„æ§åˆ¶å­—ç¬¦
        content = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
        
        # ç®€å•çš„VTTè§£æ
        lines = content.strip().split('\n')
        transcript_data = []
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # è·³è¿‡ç©ºè¡Œå’ŒWEBVTTå¤´éƒ¨
            if not line or line == 'WEBVTT' or line.startswith('NOTE'):
                i += 1
                continue
            
            # è·³è¿‡åºå·è¡Œ
            if line.isdigit():
                i += 1
                continue
            
            # è§£ææ—¶é—´æˆ³è¡Œ
            if '-->' in line:
                time_parts = line.split(' --> ')
                if len(time_parts) == 2:
                    start_time = parse_vtt_time(time_parts[0])
                    
                    # æ”¶é›†æ–‡æœ¬å†…å®¹
                    text_lines = []
                    i += 1
                    while i < len(lines) and lines[i].strip():
                        # æ¸…ç†æ¯è¡Œæ–‡æœ¬ä¸­çš„æ§åˆ¶å­—ç¬¦
                        clean_line = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', lines[i].strip())
                        if clean_line:
                            text_lines.append(clean_line)
                        i += 1
                    
                    if text_lines:
                        transcript_data.append({
                            'start': start_time,
                            'text': ' '.join(text_lines)
                        })
                else:
                    i += 1
            else:
                i += 1
        
        click.echo(f"ğŸ“Š è§£æå®Œæˆï¼Œå…± {len(transcript_data)} æ¡å­—å¹•")
        return transcript_data
        
    except Exception as e:
        click.echo(f"âŒ è§£æVTTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        raise


def parse_vtt_time(time_str):
    """è§£æVTTæ—¶é—´æ ¼å¼ä¸ºç§’æ•°"""
    # VTTæ ¼å¼: HH:MM:SS.mmm
    parts = time_str.split(':')
    if len(parts) == 3:
        hours = int(parts[0])
        minutes = int(parts[1])
        seconds = float(parts[2])
        return hours * 3600 + minutes * 60 + seconds
    return 0.0


def generate_markdown(transcript_data, video_id, original_dir):
    """ä½¿ç”¨LLMç”ŸæˆMarkdownæ–‡æ¡£"""
    click.echo("ğŸ¤– ä½¿ç”¨LLMå¤„ç†å­—å¹•æ•°æ®...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ API å¯†é’¥
        from config import Config
        if not Config.validate_config():
            click.echo("âš ï¸ æœªé…ç½® LLM API å¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆç¤ºä¾‹æ–‡æ¡£")
            result = generate_mock_result(transcript_data)
        else:
            # åˆå§‹åŒ–LLMå¤„ç†å™¨
            llm_processor = LLMProcessor()
            
            # å¤„ç†å­—å¹•æ•°æ®
            result = llm_processor.process_transcript(transcript_data)
        
        # ç”ŸæˆMarkdownå†…å®¹
        markdown_content = generate_markdown_content(result)
        
        # ä¿å­˜Markdownæ–‡ä»¶
        markdown_file = os.path.join(original_dir, f'{video_id}.transcripts.md')
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        click.echo(f"âœ… Markdownæ–‡ä»¶å·²ç”Ÿæˆ: {markdown_file}")
        return markdown_file
        
    except Exception as e:
        click.echo(f"âŒ ç”ŸæˆMarkdownæ—¶å‡ºé”™: {e}")
        raise


def generate_mock_result(transcript_data):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„ LLM ç»“æœç”¨äºæµ‹è¯•"""
    # åŸºäºå­—å¹•æ•°æ®ç”Ÿæˆç®€å•çš„ç« èŠ‚åˆ’åˆ†
    toc = []
    chapters = []
    
    if not transcript_data:
        return {"toc": [], "chapters": []}
    
    # ç®€å•çš„ç« èŠ‚åˆ’åˆ†é€»è¾‘
    current_chapter = {
        "time": format_time(transcript_data[0]['start']),
        "title": "å¼€åœºä»‹ç»",
        "content": ""
    }
    
    chapter_count = 0
    for i, item in enumerate(transcript_data):
        # æ¯30æ¡å­—å¹•ä½œä¸ºä¸€ä¸ªç« èŠ‚
        if i > 0 and i % 30 == 0:
            if current_chapter["content"]:
                chapters.append(current_chapter)
                toc.append({
                    "time": current_chapter["time"],
                    "title": current_chapter["title"]
                })
            
            chapter_count += 1
            current_chapter = {
                "time": format_time(item['start']),
                "title": f"ç« èŠ‚ {chapter_count + 1}",
                "content": ""
            }
        
        current_chapter["content"] += item['text'] + " "
    
    # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
    if current_chapter["content"]:
        chapters.append(current_chapter)
        toc.append({
            "time": current_chapter["time"],
            "title": current_chapter["title"]
        })
    
    return {
        "toc": toc,
        "chapters": chapters
    }


def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´ä¸º MM:SS æ ¼å¼"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"


def generate_markdown_content(result):
    """æ„å»ºMarkdownå†…å®¹ï¼Œå…¨éƒ¨è‹±æ–‡"""
    lines = []
    
    # åªä¿ç•™ç›®å½•ï¼Œä¸åŠ æ ‡é¢˜
    lines.append("## Table of Contents")
    for item in result.get('toc', []):
        # åªç”¨è‹±æ–‡æ ‡é¢˜ï¼Œæ²¡æœ‰åˆ™ç”¨è‹±æ–‡å ä½
        title = item.get('en_title') or item.get('title') or 'Untitled'
        if not title:
            title = 'Untitled'
        lines.append(f"- {item['time']} {title}")
    # lines.append("")
    
    # æ·»åŠ æ­£æ–‡
    lines.append("## Content")
    # lines.append("")
    
    for chapter in result.get('chapters', []):
        title = chapter.get('en_title') or chapter.get('title') or 'Untitled'
        if not title:
            title = 'Untitled'
        lines.append(f"### {chapter['time']} {title}")
        lines.append("```text")
        # æ¸…ç†å’Œè¿æ¥æ–‡æœ¬å†…å®¹ï¼Œå»é™¤ç©ºç™½è¡Œ
        content = clean_and_connect_text(chapter['content'])
        lines.append(content)
        lines.append("```")
        lines.append("")
    
    return "\n".join(lines)


def clean_and_connect_text(text):
    """æ¯å¥ä¸€æ®µï¼ŒæŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²ï¼Œæ¯å¥å•ç‹¬æˆè¡Œï¼Œæ— ç©ºç™½è¡Œã€‚"""
    import re
    # ç§»é™¤é‡å¤çš„ ```text æ ‡ç­¾
    text = re.sub(r'```text\s*```text', '```text', text)
    text = re.sub(r'```text\s*', '', text)
    text = re.sub(r'```\s*$', '', text)
    # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    # ä¿®å¤åŒå¥å·é—®é¢˜
    text = re.sub(r'\.\.+', '.', text)
    # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
    sentences = re.split(r'([.?!])', text)
    lines = []
    current = ''
    for seg in sentences:
        if seg in '.?!':
            current += seg
            lines.append(current.strip())
            current = ''
        else:
            current += seg
    # å¤„ç†æœ€åä¸€æ®µ
    if current.strip():
        lines.append(current.strip())
    # å»é™¤ç©ºç™½è¡Œ
    result = '\n'.join([line for line in lines if line])
    return result


def process_transcripts(video_id, vtt_file, original_dir):
    """å¤„ç†å­—å¹•æ–‡ä»¶"""
    click.echo(f"ğŸ“ å¤„ç†å­—å¹•æ–‡ä»¶: {vtt_file}")
    
    try:
        # è§£æVTTæ–‡ä»¶
        transcript_data = parse_vtt_file(vtt_file)
        
        # ç”ŸæˆMarkdownæ–‡æ¡£
        markdown_file = generate_markdown(transcript_data, video_id, original_dir)
        
        click.echo("âœ… å­—å¹•æ–‡ä»¶å¤„ç†å®Œæˆ")
        click.echo(f"ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£: {markdown_file}")
        
    except Exception as e:
        click.echo(f"âŒ å¤„ç†å­—å¹•æ–‡ä»¶æ—¶å‡ºé”™: {e}")


class TranscriptsCommand:
    """å­—å¹•å¤„ç†å‘½ä»¤å¤„ç†å™¨"""
    
    @staticmethod
    @click.command()
    @click.pass_context
    def transcripts(ctx):
        """å¤„ç†YouTubeè§†é¢‘å­—å¹•"""
        # ä½¿ç”¨åŸå§‹å·¥ä½œç›®å½•
        original_dir = ctx.obj.get('original_dir', '.')
        if original_dir is None:
            original_dir = '.'
        
        # æ£€æŸ¥VTTæ–‡ä»¶
        result = check_vtt_file(original_dir)
        if result is None:
            return
        
        video_id, vtt_file, url = result
        
        # å¤„ç†å­—å¹•
        process_transcripts(video_id, vtt_file, original_dir) 