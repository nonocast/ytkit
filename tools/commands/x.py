"""
YouTubeå·¥å…·é›† - xå‘½ä»¤ï¼ˆä¸¤æ­¥å¤„ç†ï¼šé¢„å¤„ç†+LLMåˆ†æï¼‰
"""
import click
import os
import re
import json
import openai
from .md import MdCommand


class XCommand:
    @staticmethod
    @click.command()
    @click.option('--step', type=click.Choice(['preprocess', 'analyze', 'both']), 
                  default='both', help='æ‰§è¡Œæ­¥éª¤ï¼špreprocess(é¢„å¤„ç†), analyze(åˆ†æ), both(å…¨éƒ¨)')
    @click.option('--batch-size', default=5, help='LLMæ‰¹é‡å¤„ç†å¤§å°')
    @click.option('--model', default='gpt-4o-mini', help='LLMæ¨¡å‹åç§°')
    @click.option('--api-key', help='OpenAI APIå¯†é’¥')
    @click.pass_context
    def x(ctx, step, batch_size, model, api_key):
        """ä¸¤æ­¥å¤„ç†ï¼šé¢„å¤„ç†å­—å¹• + LLMåˆ†æ"""
        original_dir = ctx.obj.get('original_dir') or os.getcwd()
        result = MdCommand.check_vtt_file(original_dir)
        if not result:
            ctx.exit(1)
        video_id, vtt_file, url = result
        try:
            if step in ['preprocess', 'both']:
                XCommand.step1_preprocess(video_id, vtt_file, original_dir)
            if step in ['analyze', 'both']:
                XCommand.step2_analyze(video_id, original_dir, batch_size, model, api_key)
        except Exception as e:
            click.echo(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            ctx.exit(1)

    @staticmethod
    def step1_preprocess(video_id, vtt_file, original_dir):
        """ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆpreprocessed.md"""
        click.echo("ğŸ”„ ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆé¢„å¤„ç†æ–‡ä»¶...")
        MdCommand.process_md(video_id, vtt_file, original_dir)

    @staticmethod
    def step2_analyze(video_id, original_dir, batch_size, model, api_key):
        """ç¬¬äºŒæ­¥ï¼šè°ƒç”¨LLMç”Ÿæˆåˆ†æå­—å…¸"""
        click.echo("ğŸ¤– ç¬¬äºŒæ­¥ï¼šè°ƒç”¨LLMåˆ†æ...")
        
        # æ£€æŸ¥analyzed.jsonæ˜¯å¦å·²å­˜åœ¨
        output_file = os.path.join(original_dir, f'{video_id}.analyzed.json')
        if os.path.exists(output_file):
            click.echo(f"âš ï¸ åˆ†ææ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡LLMåˆ†æ: {output_file}")
            click.echo("ğŸ’¡ å¦‚éœ€é‡æ–°åˆ†æï¼Œè¯·åˆ é™¤è¯¥æ–‡ä»¶åé‡è¯•")
            return
        
        preprocessed_file = os.path.join(original_dir, f'{video_id}.preprocessed.md')
        if not os.path.exists(preprocessed_file):
            click.echo(f"âŒ é¢„å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨: {preprocessed_file}")
            click.echo("ğŸ’¡ è¯·å…ˆè¿è¡Œç¬¬ä¸€æ­¥ç”Ÿæˆé¢„å¤„ç†æ–‡ä»¶")
            return
        sentences = XCommand.parse_preprocessed_file(preprocessed_file)
        click.echo(f"ğŸ“ è§£æåˆ° {len(sentences)} ä¸ªå¥å­")
        all_results = []
        for i in range(0, len(sentences), batch_size):
            batch = sentences[i:i+batch_size]
            click.echo(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(sentences)-1)//batch_size + 1}")
            results = XCommand.call_llm_analyze(batch, model, api_key)
            if not results:
                click.echo("âŒ LLMåˆ†æå¤±è´¥ï¼Œåœæ­¢å¤„ç†")
                return
            all_results.extend(results)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        click.echo(f"âœ… åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_file}")

    @staticmethod
    def parse_preprocessed_file(file_path):
        """è§£æpreprocessed.mdæ–‡ä»¶"""
        sentences = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                match = re.match(r'(\d{2}:\d{2})\s+\[(\d+)\]\s+(.+)', line)
                if match:
                    timestamp, sentence_id, text = match.groups()
                    sentences.append({
                        'id': sentence_id,
                        'timestamp': timestamp,
                        'sentence': text
                    })
        return sentences

    @staticmethod
    def call_llm_analyze(sentences, model, api_key):
        """è°ƒç”¨LLMåˆ†æå¥å­"""
        # æ£€æŸ¥APIå¯†é’¥
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            click.echo("âŒ æœªæ‰¾åˆ°OpenAI APIå¯†é’¥")
            click.echo("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–ä½¿ç”¨ --api-key å‚æ•°")
            return None
        
        try:
            # è®¾ç½®OpenAIå®¢æˆ·ç«¯
            client = openai.OpenAI(api_key=api_key)
            prompt = XCommand.build_analysis_prompt(sentences)
            
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­è¯­æ³•å’Œè¯æ±‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content.strip()
            try:
                results = json.loads(content)
                if isinstance(results, list):
                    return results
                else:
                    click.echo("âš ï¸ LLMè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œä¸æ˜¯æ•°ç»„æ ¼å¼")
                    return None
            except json.JSONDecodeError as e:
                click.echo(f"âš ï¸ LLMè¿”å›éJSONæ ¼å¼: {e}")
                click.echo(f"è¿”å›å†…å®¹: {content[:200]}...")
                return None
                
        except Exception as e:
            click.echo(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return None

    @staticmethod
    def build_analysis_prompt(sentences):
        """æ„å»ºLLMåˆ†æprompt"""
        prompt = """ä½ æ˜¯ä¸€ä½è‹±è¯­æ•™å­¦ä¸“å®¶ï¼Œè¯·å¯¹ä¸‹åˆ—è‹±æ–‡å¥å­è¿›è¡Œç»“æ„åŒ–åˆ†æã€‚

**é‡è¦ï¼šä½ å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚**

æ¯æ¡å¥å­åˆ†æåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- id: å¥å­ç¼–å·ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
- explanation: ä¸­æ–‡è§£é‡Šå¥å­å«ä¹‰
- syntax: ä¸­æ–‡è¯´æ˜è¯­æ³•ç»“æ„
- vocabulary: å¯¹è±¡ï¼Œkeyä¸ºå•è¯ï¼Œvalueä¸º"éŸ³æ ‡,è¯æ€§,CEFRç­‰çº§,ä¸­æ–‡å«ä¹‰"
- phrases: å¯¹è±¡ï¼Œkeyä¸ºçŸ­è¯­ï¼Œvalueä¸ºä¸­æ–‡è§£é‡Š

**è¾“å‡ºè¦æ±‚ï¼š**
1. å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„
2. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—
3. ä¸è¦ä½¿ç”¨markdownæ ¼å¼
4. ç›´æ¥è¾“å‡ºJSONæ•°ç»„

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {
    "id": "001",
    "explanation": "å¥¹å‘è§‚ä¼—é—®å¥½",
    "syntax": "ç®€å•å¥ç»“æ„",
    "vocabulary": {
      "morning": "/ËˆmÉ”ËrnÉªÅ‹/, noun, A1, æ—©æ™¨"
    },
    "phrases": {
      "Good morning": "æ—©ä¸Šå¥½"
    }
  }
]

å¥å­åˆ—è¡¨ï¼š
"""
        for sentence in sentences:
            prompt += f"{sentence['id']} {sentence['sentence']}\n"
        prompt += "\nè¯·ç›´æ¥è¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ã€‚"
        return prompt 