"""
LLMåˆ†æå™¨ - è´Ÿè´£è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œå¥å­åˆ†æ
"""
import os
import re
import json
import openai
import click


class LLMAnalyzer:
    """LLMåˆ†æå™¨ï¼Œè´Ÿè´£è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œå¥å­åˆ†æ"""
    
    def __init__(self, model='gpt-4o-mini', api_key=None):
        self.model = model
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.client = None
        if self.api_key:
            self.client = openai.OpenAI(api_key=self.api_key)
    
    def analyze_sentences(self, sentences, batch_size=5):
        """åˆ†æå¥å­åˆ—è¡¨ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœ"""
        if not self.client:
            click.echo("âŒ æœªæ‰¾åˆ°OpenAI APIå¯†é’¥")
            click.echo("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–ä½¿ç”¨ --api-key å‚æ•°")
            return None
        
        # è°ƒè¯•æ—¶åªå¤„ç†ç¬¬ä¸€æ‰¹
        batch = sentences[0:batch_size] 
        click.echo(f"ğŸ”„ å¤„ç†ç¬¬ä¸€æ‰¹ {batch_size} ä¸ªå¥å­è¿›è¡Œè°ƒè¯•")
        
        results = self._call_llm_analyze(batch)
        if not results:
            click.echo("âŒ LLMåˆ†æå¤±è´¥ï¼Œåœæ­¢å¤„ç†")
            return None
            
        return results
    
    def _call_llm_analyze(self, sentences):
        """è°ƒç”¨LLMåˆ†æå¥å­"""
        try:
            prompt = self._build_analysis_prompt(sentences)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­è¯­æ³•å’Œè¯æ±‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            content = response.choices[0].message.content.strip()
            return self._parse_response(content)
                
        except Exception as e:
            click.echo(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _parse_response(self, content):
        """è§£æLLMå“åº”"""
        try:
            results = json.loads(content)
            if isinstance(results, list):
                return results
            else:
                click.echo("âš ï¸ LLMè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œä¸æ˜¯æ•°ç»„æ ¼å¼")
                return None
        except json.JSONDecodeError as e:
            click.echo(f"âš ï¸ LLMè¿”å›éJSONæ ¼å¼: {e}")
            click.echo(f"è¿”å›å†…å®¹: {content[:200]}...")
            return None
    
    def _build_analysis_prompt(self, sentences):
        """æ„å»ºLLMåˆ†æprompt"""
        prompt = """
ä½ æ˜¯ä¸€ä½è‹±è¯­æ•™å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®æˆ‘å½“å‰çš„è‹±è¯­å­¦ä¹ æƒ…å†µï¼Œé€å¥åˆ†æä¸‹é¢è¿™æ®µè‹±æ–‡å¥å­åˆ—è¡¨ã€‚è¿”å› JSON æ•°ç»„ï¼Œæ¯å¥ä¸€ä¸ªå¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹å­—æ®µï¼š

- id: å¥å­ç¼–å·ï¼ˆå¦‚ "001"ï¼‰
- sentence: åŸå¥
- explanation: ç”¨ä¸­æ–‡è§£é‡Šè¯¥å¥å­çš„å«ä¹‰å’Œè¯­å¢ƒï¼Œå°½é‡è¿˜åŸè¯´è¯è€…çš„æƒ…ç»ªå’Œç›®çš„
- syntax: ç”¨é€šä¿—ä¸­æ–‡æŒ‡å‡ºè¯¥å¥çš„å…·ä½“è¯­æ³•ç»“æ„ï¼Œå°¤å…¶æ ‡å‡ºä»¥ä¸‹ç»“æ„ï¼šå®¾è¯­ä»å¥ã€éè°“è¯­ç»“æ„ã€æƒ…æ€ç»“æ„ã€æ¯”è¾ƒçŠ¶è¯­ã€å¼ºè°ƒå¥ç­‰ï¼›è¯·é¿å…ç¬¼ç»Ÿæè¿°å¦‚"å¤åˆå¥"
- vocabulary: ä¸€ä¸ª objectï¼Œåˆ—å‡ºè¯¥å¥ä¸­æˆ‘å¯èƒ½ä¸ç†Ÿæ‚‰çš„ä¸­é«˜çº§è¯æ±‡ï¼ˆCEFR B2åŠä»¥ä¸Šï¼Œæˆ–è¯­ä¹‰/ç”¨æ³•æ˜“æ··çš„è¯ï¼‰ï¼Œkey æ˜¯å•è¯ï¼Œvalue ä¸º "éŸ³æ ‡, è¯æ€§, CEFRç­‰çº§, ä¸­æ–‡å«ä¹‰"
- phrases: ä¸€ä¸ª objectï¼Œåˆ—å‡ºè¯¥å¥ä¸­å€¼å¾—å­¦ä¹ çš„**å›ºå®šæ­é…ã€åŠ¨è¯çŸ­è¯­ã€å£è¯­è¡¨è¾¾ã€å¸¸è§å¥å‹ç»“æ„**ï¼Œkey æ˜¯çŸ­è¯­ï¼Œvalue ä¸ºä¸­æ–‡è§£é‡Šæˆ–å¸¸ç”¨è¯­å¢ƒè¯´æ˜

æˆ‘çš„è‹±è¯­èƒŒæ™¯ï¼š
- è¯æ±‡é‡çº¦ 5000ï¼ŒA1â€“B1 è¯æ±‡åŸºæœ¬æŒæ¡ï¼›
- åŠ¨è¯çŸ­è¯­ã€å¥å­ç»“æ„å’Œå£è¯­è¡¨è¾¾æ˜¯æˆ‘ä¸»è¦çš„å¼±é¡¹ï¼›
- å¸Œæœ›æå‡å¥æ³•ç†è§£å’ŒçœŸå®è¯­å¢ƒè¡¨è¾¾èƒ½åŠ›ã€‚

è¯·ä¸è¦è¾“å‡ºæˆ‘å·²ç»æŒæ¡çš„åŸºç¡€è¯ï¼ˆå¦‚: fun, love, kind, idea ç­‰ï¼‰ã€‚è¯·åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦é¢å¤–æ–‡å­—è¯´æ˜ã€‚

**é‡è¦ï¼šä½ å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚**

**è¾“å‡ºè¦æ±‚ï¼š**
1. å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„
2. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—
3. ä¸è¦ä½¿ç”¨markdownæ ¼å¼
4. ç›´æ¥è¾“å‡ºJSONæ•°ç»„

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {
    "id": "005",
    "sentence": "Like I know in advance kind of what I want to do. But to be honest, I have no idea what I'm going to do today.",
    "explanation": "å¥¹è¯´å¹³å¸¸å¥¹éƒ½ä¼šæå‰æœ‰äº›æƒ³æ³•ï¼Œä½†ä»Šå¤©å¥¹å®Œå…¨æ²¡æœ‰è®¡åˆ’ï¼Œè¿™æ˜¯è¡¨è¾¾è½»å¾®ç„¦è™‘æˆ–æ”¾æ¾éšæ€§çš„æƒ…ç»ªã€‚",
    "syntax": "ç¬¬ä¸€å¥æ˜¯å®¾è¯­ä»å¥ï¼ˆwhat I want to doï¼‰ï¼Œç”± like å¼•å¯¼çš„è¯­æ°”å¥ï¼›ç¬¬äºŒå¥æ˜¯ä¸»å¥ + what å¼•å¯¼çš„å®¾è¯­ä»å¥ã€‚",
    "vocabulary": {
      "no idea": "/nÉ™ÊŠ aÉªËˆdÉªÉ™/, phrase, B2, å®Œå…¨ä¸çŸ¥é“ï¼Œè¡¨è¾¾å®Œå…¨æ²¡æœ‰å¤´ç»ª"
    },
    "phrases": {
      "like I know": "åƒæ˜¯æˆ‘çŸ¥é“â€¦ï¼Œå¸¸ç”¨äºå¼•å…¥ä¸€ç§ä¸ç¡®å®š/éšæ„è¯­æ°”",
      "in advance": "æå‰ï¼Œå¸¸ç”¨äºè®¡åˆ’æˆ–å‡†å¤‡åœºæ™¯", 
      "kind of": "æœ‰ç‚¹ï¼Œæ¨¡ç³Šè¯­æ°”ï¼Œé™ä½è¯­æ°”å¼ºåº¦",
      "to be honest": "è¯´å®è¯ï¼Œå¸¸ç”¨äºè¡¨è¾¾ä¸ªäººçœŸå®æƒ…ç»ªæˆ–è½¬æŠ˜",
      "I have no idea": "æˆ‘ä¸€ç‚¹å¤´ç»ªéƒ½æ²¡æœ‰ï¼Œéå¸¸å¸¸ç”¨çš„è¡¨è¾¾å®Œå…¨ä¸çŸ¥é“"
    }
  }
]

å¥å­åˆ—è¡¨ï¼š
"""
        for sentence in sentences:
            prompt += f"{sentence['id']} {sentence['sentence']}\n"
        prompt += "\nè¯·ç›´æ¥è¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ã€‚"
        return prompt


class PreprocessedFileParser:
    """é¢„å¤„ç†æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_preprocessed_file(file_path):
        """è§£æpreprocessed.mdæ–‡ä»¶"""
        sentences = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                match = re.match(r'(\d{2}:\d{2})\s+\[(\d+)\]\s+(.+)', line)
                if match:
                    timestamp, sentence_id, text = match.groups()
                    sentences.append({
                        'id': sentence_id,
                        'timestamp': timestamp,
                        'sentence': text
                    })
        return sentences 